hydra:
  job:
    chdir: False

train:
  dataset_name: ["JasiekKaczmarczyk/giant-midi-sustain-quantized", "roszcz/pfa-sustain-quantized-7-7-7", "JasiekKaczmarczyk/maestro-sustain-quantized"] # huggingface dataset
  batch_size: 1024
  num_workers: 8
  lr: 3e-4
  weight_decay: 0.01
  num_epochs: 10
  device: "cuda"
  precision: "16-mixed" # not implemented yet
  overfit_single_batch: False

paths:
  save_ckpt_dir: "checkpoints" # directory where checkpoints will be saved
  load_ckpt_path: null # if not None, specifies path to model state dict which will be loaded
  cond_model_repo_id: "roszcz/midi-clip"
  cond_model_ckpt_path: "midi-clip-batch-256-2023-08-27-10-14.ckpt"
  log_dir: "logs"
  hf_repo_id: null # repo id to upload model to huggingface if null model is not uploaded

models:
  unet:
    in_out_channels: 3 # input and output channels
    dim: 64 # initial number of unet channels (will be multiplied by dim_mults)
    dim_mults: [1, 2, 4, 4]
    kernel_size: 7
    num_resnet_groups: 4
  forward_diffusion:
    beta_start: 0.0001
    beta_end: 0.02
    timesteps: 256
    schedule_type: "sigmoid" # schedule type: cosine, linear, quadratic, sigmoid

logger:
  run_name: midi-diffusion-velocity-time-${now:%Y-%m-%d-%H-%M}
  log_every_n_steps: 50
